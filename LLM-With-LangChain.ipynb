{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What data scientist did the data scientist?\n",
      "\n",
      "The data scientist did the data scientist?\n",
      "\n",
      "Because the data scientist knew how to input the data, they were able to get a better understanding of it.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\", openai_api_key=API_KEY)\n",
    "\n",
    "print(llm(\"Tell me a joke about data scientist\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# We will be using OpenAI's LLM for this project\n",
    "# from langchain import HuggingFaceHub\n",
    "#\n",
    "# llm = HuggingFaceHub(repo_id = \"google/flan-t5-xl\", huggingfacehub_api_token = API_KEY)\n",
    "#\n",
    "# print(llm(\"Tell me a joke about data scientist\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "llm_response = llm.generate(['Tell me a joke about data scientist',\n",
    "                             'Tell me a joke about recruiter',\n",
    "                             'Tell me a joke about psychologist'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Generation(text='\\n\\nWhy did the data scientist say that she never wanted to be known as the data scientist?\\n\\nBecause she wanted people to think she was data rich!')"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response.generations[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "Generation(text='\\n\\nWhy did the recruiter go to the shop?\\n\\nTo buy a tool.')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response.generations[1][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Generation(text='\\n\\nWhy did the psychologist say that he never did anything\\n\\nBecause he knew that would be the last thing he would do.')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response.generations[2][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Output: \n",
      "\n",
      "1. Explore the Louvre Museum and view the Mona Lisa: The Louvre Museum is the world's largest art museum and a historic monument in Paris, France. The museum is home to the iconic Mona Lisa painting, as well as other works of art from the Renaissance and beyond. \n",
      "\n",
      "2. Visit the Eiffel Tower: The Eiffel Tower is an iconic landmark in Paris, and is one of the most recognizable structures in the world. Take in the breathtaking views from the top of the tower and enjoy the surrounding gardens.\n",
      "\n",
      "3. Enjoy a Seine River Cruise: Embark on a relaxing cruise along the River Seine and take in the sights of Paris. Admire the stunning architecture of the city from a unique perspective and enjoy a romantic evening out.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "USER_INPUT = 'Paris'\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=API_KEY)\n",
    "\n",
    "template = \"\"\" I am travelling to {location}. What are the top 3 things I can do while I am there. Be very specific and respond as three bullet points \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(location=USER_INPUT)\n",
    "\n",
    "print(f\"LLM Output: {llm(final_prompt)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "\n",
      "Toronto.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m\n",
      "\n",
      "1. Explore the CN Tower \n",
      "2. Take a stroll along the Harbourfront \n",
      "3. Visit the Royal Ontario Museum\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished SimpleSequentialChain chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Letâ€™s see an example of the first scenario where we will use the output from the first LLM as an input to the second LLM.\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=API_KEY)\n",
    "\n",
    "template1 = \"What is the most popular city in {country} for tourists? Just return the name of the city\"\n",
    "template2 = \"What are the top three things to do in this: {city} for tourists. Just return the answer as three bullet points.\"\n",
    "\n",
    "first_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=template1)\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"city\"],\n",
    "    template=template2)\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "# Combine the first and the second chain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "\n",
    "final_answer = overall_chain.run(\"Canada\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
